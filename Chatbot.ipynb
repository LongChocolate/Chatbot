{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00c0f6bb",
      "metadata": {
        "id": "00c0f6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a489106c-7eea-427c-c532-3d6899623240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import tensorflow as tf\n",
        "from  sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56accd1a",
      "metadata": {
        "id": "56accd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "abf40522-9d89-43e1-92f9-cc1f193de5a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              user_a                            user_b\n",
              "0                Thích mẫu người nào      Dễ thương, tóc dài, da trắng\n",
              "1                  Có crush ai không                 Có 1 bạn cùng lớp\n",
              "2           Tại sao lại thích bạn dó  Vì đáp ứng những yêu cầu của tao\n",
              "3            Có hay nói chuyện không            Hay nhắn tin messenger\n",
              "4  Bạn kia có bắt chuyện trước không                        Có đôi khi"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb4ac2ea-f497-409d-9e8a-acbc8f498941\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_a</th>\n",
              "      <th>user_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thích mẫu người nào</td>\n",
              "      <td>Dễ thương, tóc dài, da trắng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Có crush ai không</td>\n",
              "      <td>Có 1 bạn cùng lớp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tại sao lại thích bạn dó</td>\n",
              "      <td>Vì đáp ứng những yêu cầu của tao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Có hay nói chuyện không</td>\n",
              "      <td>Hay nhắn tin messenger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bạn kia có bắt chuyện trước không</td>\n",
              "      <td>Có đôi khi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb4ac2ea-f497-409d-9e8a-acbc8f498941')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb4ac2ea-f497-409d-9e8a-acbc8f498941 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb4ac2ea-f497-409d-9e8a-acbc8f498941');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df1 = pd.read_csv('dữ liệu chatbot question-answer short style.csv',index_col = 0)\n",
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525aa936",
      "metadata": {
        "id": "525aa936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2d9fd79f-67e3-4349-a4d0-6bba725f8e74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              user_a  \\\n",
              "0                                        bạn tên gì?   \n",
              "1                   Tui tên Nam <eos> Bạn học ở đâu?   \n",
              "2         tui học ở TDTU luôn <eos> Bạn học ngành gì   \n",
              "3                          Chuyên ngành gì vậy bạn ?   \n",
              "4  mình học Quản Trị Kinh Doanh <eos> Bạn là ngườ...   \n",
              "\n",
              "                                              user_b  \n",
              "0             Mình tên Trường <eos> còn bạn tên gì?   \n",
              "1  tui học ở TDTU nè <eos> còn bạn học ở trường n...  \n",
              "2                       mình học Công Nghệ Thông Tin  \n",
              "3  mình học bên Kỹ Thuật Phần Mềm á <eos> còn bạn...  \n",
              "4  Mình là người Đồng tháp <eos> bạn biết Đồng Th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4a2298e-1278-45fc-b7df-76525b44d9eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_a</th>\n",
              "      <th>user_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bạn tên gì?</td>\n",
              "      <td>Mình tên Trường &lt;eos&gt; còn bạn tên gì?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tui tên Nam &lt;eos&gt; Bạn học ở đâu?</td>\n",
              "      <td>tui học ở TDTU nè &lt;eos&gt; còn bạn học ở trường n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tui học ở TDTU luôn &lt;eos&gt; Bạn học ngành gì</td>\n",
              "      <td>mình học Công Nghệ Thông Tin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chuyên ngành gì vậy bạn ?</td>\n",
              "      <td>mình học bên Kỹ Thuật Phần Mềm á &lt;eos&gt; còn bạn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mình học Quản Trị Kinh Doanh &lt;eos&gt; Bạn là ngườ...</td>\n",
              "      <td>Mình là người Đồng tháp &lt;eos&gt; bạn biết Đồng Th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4a2298e-1278-45fc-b7df-76525b44d9eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4a2298e-1278-45fc-b7df-76525b44d9eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4a2298e-1278-45fc-b7df-76525b44d9eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df2 = pd.read_csv('chatbot data.csv',index_col = 0)\n",
        "df2.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreProcessing"
      ],
      "metadata": {
        "id": "01kU70D_xIq9"
      },
      "id": "01kU70D_xIq9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4bed7d9",
      "metadata": {
        "id": "f4bed7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f6d701-ec28-4221-ea6e-d4b3b80c9ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['bạn', 'tên', 'gì'], ['mình', 'tên', 'trường']], [['còn', 'bạn', 'tên', 'gì'], ['tui', 'tên', 'nam']], [['bạn', 'học', 'ở', 'đâu'], ['tui', 'học', 'ở', 'tdtu', 'nè']], [['còn', 'bạn', 'học', 'ở', 'trường', 'nào', ''], ['tui', 'học', 'ở', 'tdtu', 'luôn']], [['bạn', 'học', 'ngành', 'gì'], ['mình', 'học', 'công', 'nghệ', 'thông', 'tin']], [['chuyên', 'ngành', 'gì', 'vậy', 'bạn', ''], ['mình', 'học', 'bên', 'kỹ', 'thuật', 'phần', 'mềm', 'á']], [['còn', 'bạn', 'học', 'ngành', 'gì', ''], ['mình', 'học', 'quản', 'trị', 'kinh', 'doanh']], [['bạn', 'là', 'người', 'ở', 'đâu', 'vậy', ''], ['mình', 'là', 'người', 'đồng', 'tháp']], [['bạn', 'biết', 'đồng', 'tháp', 'không', ''], ['mình', 'biết,', 'đồng', 'tháp', 'dưới', 'miền', 'tây', 'đúng', 'không', '?']], [['mình', 'biết', 'đồng', 'tháp', 'dưới', 'miền', 'tây', 'đúng', 'không', ''], ['đúng', 'rồi', 'đó']]]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "pair = []\n",
        "for i in range(df2.shape[0]):\n",
        "    ques = re.sub(r'[^\\w\\d\\s]','',str(df2.iloc[i]['user_a']).strip().lower())\n",
        "    ans = re.sub(r'[^\\w\\d\\s]','',str(df2.iloc[i]['user_b']).strip().lower())\n",
        "    user_a = ques.split(' eos ')\n",
        "    user_b = ans.split(' eos ')\n",
        "\n",
        "    if len(user_b) > 1:\n",
        "        #lấy câu hỏi user_a vs câu trl đầu tiên trong user_b\n",
        "        pair.append( [user_a[-1].split(' ') , user_b[0].split(' ')] )\n",
        "        #lấy câu sau của user_b làm câu hỏi và câu tiếp theo của user_a làm cau trl\n",
        "        pair.append( [user_b[-1].split(' ') , df2.iloc[i+1]['user_a'].strip().split(' <eos> ')[0].lower().split(' ')] )\n",
        "    elif user_b[0] != 'nan':\n",
        "        pair.append( [user_a[-1].split(' ') , user_b[0].split(' ')] )\n",
        "\n",
        "    #một dố câu bị NaN thì bỏ qua\n",
        "print(pair[:10])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041af8ab",
      "metadata": {
        "id": "041af8ab"
      },
      "outputs": [],
      "source": [
        "df1 = df1.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccebf0d1",
      "metadata": {
        "id": "ccebf0d1"
      },
      "outputs": [],
      "source": [
        "for i in range(df1.shape[0]-3000):\n",
        "    #thêm data của data1 vào list\n",
        "    ques = re.sub(r'[^\\w\\d\\s]','',df1.iloc[i]['user_a'].strip().lower())\n",
        "    ans = re.sub(r'[^\\w\\d\\s]','',df1.iloc[i]['user_b'].strip().lower())\n",
        "    pair.append([ques.split(' '), ans.split(' ')])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pair[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQj-hWasNA92",
        "outputId": "6d0f4890-c721-41d6-914e-2f601070e576"
      },
      "id": "YQj-hWasNA92",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['bạn', 'tên', 'gì'], ['mình', 'tên', 'trường']], [['còn', 'bạn', 'tên', 'gì'], ['tui', 'tên', 'nam']], [['bạn', 'học', 'ở', 'đâu'], ['tui', 'học', 'ở', 'tdtu', 'nè']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU SCORE"
      ],
      "metadata": {
        "id": "jDwumh8-xSMh"
      },
      "id": "jDwumh8-xSMh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b00711f",
      "metadata": {
        "id": "6b00711f"
      },
      "outputs": [],
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "smooth = bleu.SmoothingFunction().method4\n",
        "\n",
        "def BleuScore(ques):\n",
        "    scores = [bleu.sentence_bleu([pair[i][0]], ques, weights=(0.5,0.5,0), smoothing_function= smooth) for i in range(len(pair))]\n",
        "    s_max = max(scores)\n",
        "    ans = pair[scores.index(s_max)][1]\n",
        "    return ' '.join(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4cce1b",
      "metadata": {
        "id": "ba4cce1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0867df-3a95-4bf3-b433-5c9fd45fd69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: bạn tên là gì\n",
            "Answer: tui tên là đậu\n",
            "Question: q\n"
          ]
        }
      ],
      "source": [
        "chat = True\n",
        "while chat:\n",
        "    ques = str(input('Question: '))\n",
        "    if ques == 'q':\n",
        "        chat = False\n",
        "    else:\n",
        "        ans = BleuScore(ques.split())\n",
        "        print('Answer: {}'.format(ans))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n"
      ],
      "metadata": {
        "id": "cW74M6HixAHV"
      },
      "id": "cW74M6HixAHV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ad4adc",
      "metadata": {
        "id": "73ad4adc"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dae730",
      "metadata": {
        "id": "d1dae730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d00133b-8769-4c4e-86d3-2dbd5d732c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4541\n",
            "4541\n",
            "[['bạn', 'tên', 'gì'], ['còn', 'bạn', 'tên', 'gì'], ['bạn', 'học', 'ở', 'đâu']]\n"
          ]
        }
      ],
      "source": [
        "question_tokens = [i[0] for i in pair]\n",
        "print(len(pair))\n",
        "print(len(question_tokens))\n",
        "print(question_tokens[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBOW\n"
      ],
      "metadata": {
        "id": "vA-gzKT0yVlj"
      },
      "id": "vA-gzKT0yVlj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5526167",
      "metadata": {
        "id": "d5526167"
      },
      "outputs": [],
      "source": [
        "#CBOW\n",
        "crow = Word2Vec(question_tokens,size=150, window=5, min_count=2, workers=4, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd46c6a",
      "metadata": {
        "id": "efd46c6a"
      },
      "outputs": [],
      "source": [
        "#hàm chuyển word thành vecter\n",
        "def word2vecCrow(seq):\n",
        "    vec = np.zeros(150,dtype='float')\n",
        "    for word in seq:\n",
        "        if word not in crow.wv:\n",
        "            continue\n",
        "        vec += crow.wv[word]\n",
        "    return vec/len(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d643e423",
      "metadata": {
        "id": "d643e423"
      },
      "outputs": [],
      "source": [
        "w2c = [word2vecCrow(i) for i in question_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6fad48",
      "metadata": {
        "id": "bb6fad48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07a616a-4c20-440e-b251-9f67e3e690af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hải sản\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "vec_input = word2vecCrow(\"bạn học ở đâu và ngành gì\".split())\n",
        "q = euclidean_distances([vec_input],w2c)\n",
        "predict = np.argmin(q,axis=1)\n",
        "print(' '.join(pair[predict[0]][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skip Grams"
      ],
      "metadata": {
        "id": "X1-zAfLQyeDc"
      },
      "id": "X1-zAfLQyeDc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ffdd02",
      "metadata": {
        "id": "31ffdd02"
      },
      "outputs": [],
      "source": [
        "#Skip-grams\n",
        "skip = Word2Vec(question_tokens,size=150, window=5, min_count=2, workers=4, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a791df25",
      "metadata": {
        "id": "a791df25"
      },
      "outputs": [],
      "source": [
        "def word2vecSkip(seq):\n",
        "    vec = np.ones(150,dtype='float')\n",
        "    for word in seq:\n",
        "        deno = np.ones(150,dtype='float')\n",
        "        if word not in skip.wv:\n",
        "            continue\n",
        "        vec += crow.wv[word]\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2c_Skip = [word2vecSkip(i) for i in question_tokens]"
      ],
      "metadata": {
        "id": "cQz3IEAcmnp3"
      },
      "id": "cQz3IEAcmnp3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a96dbd",
      "metadata": {
        "id": "00a96dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d5f247-1007-41cd-becb-09b13b18d452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tớ học đại học tôn đức thắng\n"
          ]
        }
      ],
      "source": [
        "vec_input = word2vecSkip(\"bạn học trường nào\".split())\n",
        "q = euclidean_distances([vec_input],w2c_Skip)\n",
        "predict = np.argmin(q,axis=1)\n",
        "print(' '.join(pair[predict[0]][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pad_Sequences"
      ],
      "metadata": {
        "id": "LMH2r-0-we-U"
      },
      "id": "LMH2r-0-we-U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8234b6f1",
      "metadata": {
        "id": "8234b6f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00319c78-fa6a-47e2-c226-f2a83c9b9e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<start>', 'mình', 'tên', 'trường', '<end>'], ['<start>', 'tui', 'tên', 'nam', '<end>'], ['<start>', 'tui', 'học', 'ở', 'tdtu', 'nè', '<end>']]\n"
          ]
        }
      ],
      "source": [
        "ans_tokens = [['<start>']+ i[1]+['<end>'] for i in pair]\n",
        "print(ans_tokens[:3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_tokens = [['<start>']+ i+['<end>'] for i in question_tokens]\n",
        "print(question_tokens[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwn9TZNog-su",
        "outputId": "2f6afaa0-1849-4940-b801-57579ae4858e"
      },
      "id": "Cwn9TZNog-su",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<start>', 'bạn', 'tên', 'gì', '<end>'], ['<start>', 'còn', 'bạn', 'tên', 'gì', '<end>'], ['<start>', 'bạn', 'học', 'ở', 'đâu', '<end>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a0563b",
      "metadata": {
        "id": "74a0563b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dec1d2e-b992-4d57-b573-ed47efdc942f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE : 3104\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import preprocessing, utils\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(question_tokens + ans_tokens)\n",
        "VOCAB_SIZE = len(tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96464bb",
      "metadata": {
        "id": "f96464bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3528816-4057-42c7-e305-c5956d104b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4541, 73)\n"
          ]
        }
      ],
      "source": [
        "#encoder dữ liệu đầu vào\n",
        "tokenized_questions = tokenizer.texts_to_sequences(question_tokens)\n",
        "maxlen_questions = max( [len(x) for x in tokenized_questions ])\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "print(encoder_input_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "982a6cab",
      "metadata": {
        "id": "982a6cab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44793ec8-7163-4862-9c17-e1dec2d2d656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4541, 36)\n"
          ]
        }
      ],
      "source": [
        "# decoder dữ liệu đầu vào\n",
        "tokenized_answers = tokenizer.texts_to_sequences(ans_tokens)\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answer = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answer )\n",
        "print( decoder_input_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203535e2",
      "metadata": {
        "id": "203535e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b9f1a3-7173-4824-cf35-0692d014d115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4541, 36, 3104)\n"
          ]
        }
      ],
      "source": [
        "tokenized_answers = tokenizer.texts_to_sequences(ans_tokens)\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "onehot_answers = utils.to_categorical( padded_answers)\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "Ib9mq4R6wZ3H"
      },
      "id": "Ib9mq4R6wZ3H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62011ee",
      "metadata": {
        "id": "b62011ee"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(maxlen_questions,))\n",
        "encoder_embedding = Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(200 , return_state=True )(encoder_embedding)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(maxlen_answers,))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_embedding = Embedding(VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = LSTM(200, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab1b7c7",
      "metadata": {
        "id": "0ab1b7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c69cdd8-679e-4177-a3b4-a3634a12910e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 73)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 36)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 73, 200)      620800      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 36, 200)      620800      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 36, 200),    320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 36, 3104)     623904      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,507,104\n",
            "Trainable params: 2,507,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d899cb9",
      "metadata": {
        "id": "5d899cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794dc8e2-2285-47f3-f0b1-e1e407b827a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "91/91 [==============================] - 11s 29ms/step - loss: 0.9881\n",
            "Epoch 2/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.8836\n",
            "Epoch 3/150\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.8575\n",
            "Epoch 4/150\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.8346\n",
            "Epoch 5/150\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.8117\n",
            "Epoch 6/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.7918\n",
            "Epoch 7/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.7729\n",
            "Epoch 8/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.7548\n",
            "Epoch 9/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.7363\n",
            "Epoch 10/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.7186\n",
            "Epoch 11/150\n",
            "91/91 [==============================] - 3s 31ms/step - loss: 0.7008\n",
            "Epoch 12/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6833\n",
            "Epoch 13/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6655\n",
            "Epoch 14/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6482\n",
            "Epoch 15/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6306\n",
            "Epoch 16/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.6139\n",
            "Epoch 17/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5969\n",
            "Epoch 18/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5797\n",
            "Epoch 19/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5625\n",
            "Epoch 20/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5463\n",
            "Epoch 21/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5300\n",
            "Epoch 22/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.5134\n",
            "Epoch 23/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4974\n",
            "Epoch 24/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4813\n",
            "Epoch 25/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4657\n",
            "Epoch 26/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4504\n",
            "Epoch 27/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4354\n",
            "Epoch 28/150\n",
            "91/91 [==============================] - 3s 36ms/step - loss: 0.4204\n",
            "Epoch 29/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.4055\n",
            "Epoch 30/150\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.3904\n",
            "Epoch 31/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3763\n",
            "Epoch 32/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.3613\n",
            "Epoch 33/150\n",
            "91/91 [==============================] - 4s 47ms/step - loss: 0.3474\n",
            "Epoch 34/150\n",
            "91/91 [==============================] - 5s 50ms/step - loss: 0.3343\n",
            "Epoch 35/150\n",
            "91/91 [==============================] - 4s 49ms/step - loss: 0.3206\n",
            "Epoch 36/150\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 0.3070\n",
            "Epoch 37/150\n",
            "91/91 [==============================] - 4s 45ms/step - loss: 0.2944\n",
            "Epoch 38/150\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.2811\n",
            "Epoch 39/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2688\n",
            "Epoch 40/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2573\n",
            "Epoch 41/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2454\n",
            "Epoch 42/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2344\n",
            "Epoch 43/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2225\n",
            "Epoch 44/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2123\n",
            "Epoch 45/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.2017\n",
            "Epoch 46/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1918\n",
            "Epoch 47/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1825\n",
            "Epoch 48/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1724\n",
            "Epoch 49/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1638\n",
            "Epoch 50/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.1549\n",
            "Epoch 51/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.1469\n",
            "Epoch 52/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.1384\n",
            "Epoch 53/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.1311\n",
            "Epoch 54/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1233\n",
            "Epoch 55/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1159\n",
            "Epoch 56/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1097\n",
            "Epoch 57/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.1038\n",
            "Epoch 58/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0974\n",
            "Epoch 59/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0919\n",
            "Epoch 60/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0864\n",
            "Epoch 61/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0817\n",
            "Epoch 62/150\n",
            "91/91 [==============================] - 3s 28ms/step - loss: 0.0773\n",
            "Epoch 63/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0727\n",
            "Epoch 64/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0689\n",
            "Epoch 65/150\n",
            "91/91 [==============================] - 4s 48ms/step - loss: 0.0650\n",
            "Epoch 66/150\n",
            "91/91 [==============================] - 4s 43ms/step - loss: 0.0615\n",
            "Epoch 67/150\n",
            "91/91 [==============================] - 4s 46ms/step - loss: 0.0579\n",
            "Epoch 68/150\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.0549\n",
            "Epoch 69/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0517\n",
            "Epoch 70/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0492\n",
            "Epoch 71/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0470\n",
            "Epoch 72/150\n",
            "91/91 [==============================] - 3s 32ms/step - loss: 0.0447\n",
            "Epoch 73/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0425\n",
            "Epoch 74/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0405\n",
            "Epoch 75/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0388\n",
            "Epoch 76/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0370\n",
            "Epoch 77/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0355\n",
            "Epoch 78/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0339\n",
            "Epoch 79/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0324\n",
            "Epoch 80/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0313\n",
            "Epoch 81/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0301\n",
            "Epoch 82/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0291\n",
            "Epoch 83/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0280\n",
            "Epoch 84/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0271\n",
            "Epoch 85/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0261\n",
            "Epoch 86/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0255\n",
            "Epoch 87/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0250\n",
            "Epoch 88/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0241\n",
            "Epoch 89/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0232\n",
            "Epoch 90/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0226\n",
            "Epoch 91/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0222\n",
            "Epoch 92/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0218\n",
            "Epoch 93/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0213\n",
            "Epoch 94/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0210\n",
            "Epoch 95/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0205\n",
            "Epoch 96/150\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.0200\n",
            "Epoch 97/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0196\n",
            "Epoch 98/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0193\n",
            "Epoch 99/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0192\n",
            "Epoch 100/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0189\n",
            "Epoch 101/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0186\n",
            "Epoch 102/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0184\n",
            "Epoch 103/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0181\n",
            "Epoch 104/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0180\n",
            "Epoch 105/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0177\n",
            "Epoch 106/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0175\n",
            "Epoch 107/150\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.0173\n",
            "Epoch 108/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0171\n",
            "Epoch 109/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0169\n",
            "Epoch 110/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0168\n",
            "Epoch 111/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0167\n",
            "Epoch 112/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0166\n",
            "Epoch 113/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0164\n",
            "Epoch 114/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0164\n",
            "Epoch 115/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0162\n",
            "Epoch 116/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0161\n",
            "Epoch 117/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0160\n",
            "Epoch 118/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0160\n",
            "Epoch 119/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0158\n",
            "Epoch 120/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0156\n",
            "Epoch 121/150\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.0156\n",
            "Epoch 122/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0154\n",
            "Epoch 123/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0155\n",
            "Epoch 124/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0153\n",
            "Epoch 125/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0152\n",
            "Epoch 126/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0152\n",
            "Epoch 127/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0152\n",
            "Epoch 128/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0151\n",
            "Epoch 129/150\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.0151\n",
            "Epoch 130/150\n",
            "91/91 [==============================] - 4s 48ms/step - loss: 0.0150\n",
            "Epoch 131/150\n",
            "91/91 [==============================] - 4s 44ms/step - loss: 0.0150\n",
            "Epoch 132/150\n",
            "91/91 [==============================] - 4s 40ms/step - loss: 0.0149\n",
            "Epoch 133/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0150\n",
            "Epoch 134/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0149\n",
            "Epoch 135/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0147\n",
            "Epoch 136/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0147\n",
            "Epoch 137/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0145\n",
            "Epoch 138/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0146\n",
            "Epoch 139/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0147\n",
            "Epoch 140/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0144\n",
            "Epoch 141/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0146\n",
            "Epoch 142/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0144\n",
            "Epoch 143/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0145\n",
            "Epoch 144/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0144\n",
            "Epoch 145/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0144\n",
            "Epoch 146/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0144\n",
            "Epoch 147/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0144\n",
            "Epoch 148/150\n",
            "91/91 [==============================] - 3s 29ms/step - loss: 0.0143\n",
            "Epoch 149/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0143\n",
            "Epoch 150/150\n",
            "91/91 [==============================] - 3s 30ms/step - loss: 0.0143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cda66a890>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
        "          batch_size=50,\n",
        "          epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "4VhzV_CifVuv"
      },
      "id": "4VhzV_CifVuv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319ba461",
      "metadata": {
        "id": "319ba461"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(200,))\n",
        "decoder_state_input_c = Input(shape=(200,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " encoder_model = load_model('encoder.h5')\n",
        " decoder_model = load_model('decoder.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzni5Gcblldz",
        "outputId": "786aa63f-cea7-440f-81c9-5c93489c7cc2"
      },
      "id": "jzni5Gcblldz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3ae7ef",
      "metadata": {
        "id": "6e3ae7ef"
      },
      "outputs": [],
      "source": [
        "def str_tokens(sentence):\n",
        "  words = ['<start>'] + sentence.lower().split() + ['<end>']\n",
        "  tokens_list = list()\n",
        "  for word in words:\n",
        "    tokens_list.append(tokenizer.word_index[word])\n",
        "  return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post' )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states_values = encoder_model.predict(str_tokens( input( 'Enter question : ' ) ) )\n",
        "empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "empty_target_seq[0, 0] = tokenizer.word_index['<start>']\n",
        "condition = True\n",
        "decoded_translation = ''\n",
        "while condition :\n",
        "    dec_outputs , h , c = decoder_model.predict([ empty_target_seq ] + states_values )\n",
        "    sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "    sampled_word = None\n",
        "    for word , index in tokenizer.word_index.items() :\n",
        "        if sampled_word_index == index :\n",
        "            decoded_translation += ' {}'.format( word )\n",
        "            sampled_word = word\n",
        "\n",
        "    if sampled_word == '<end>' or len(decoded_translation.split()) > maxlen_answers:\n",
        "        condition = False\n",
        "        if sampled_word == '<end>':\n",
        "          decoded_translation = decoded_translation[:-5]\n",
        "\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "    states_values = [ h , c ]\n",
        "\n",
        "print( decoded_translation )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxuXrf6CWzN",
        "outputId": "618a09e5-203f-4b0b-bc5e-78b3a99ff412"
      },
      "id": "nYxuXrf6CWzN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter question : bạn quê ở đâu\n",
            " mình quê ở tiền giang \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer\n"
      ],
      "metadata": {
        "id": "bvxuqDqhnnnz"
      },
      "id": "bvxuqDqhnnnz"
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n"
      ],
      "metadata": {
        "id": "GKFUS9XJnphs"
      },
      "id": "GKFUS9XJnphs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.enc = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        enc_output = self.enc(out1)\n",
        "        enc_output = self.dropout2(enc_output, training=training)\n",
        "        return self.layernorm2(out1 + enc_output)"
      ],
      "metadata": {
        "id": "wyDCqZTuj6e0"
      },
      "id": "wyDCqZTuj6e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.enc = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        enc_out = self.enc(enc_out_norm)\n",
        "        enc_out_norm = self.layernorm3(enc_out_norm + self.enc_dropout(enc_out))\n",
        "        return enc_out_norm"
      ],
      "metadata": {
        "id": "9evWW_G7j6pe"
      },
      "id": "9evWW_G7j6pe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e1c51f",
      "metadata": {
        "id": "b4e1c51f"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=50,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.num_classes = num_classes\n",
        "        self.source_maxlen=source_maxlen\n",
        "        self.target_maxlen=target_maxlen\n",
        "        self.enc_input = TokenEmbedding(\n",
        "            num_vocab=VOCAB_SIZE,num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=VOCAB_SIZE, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source)\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 != 0:\n",
        "            return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"]\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        print(preds)\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "DPy67fzpR4Xr"
      },
      "id": "DPy67fzpR4Xr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\" linear warm up - linear decay \"\"\"\n",
        "        warmup_lr = (\n",
        "            self.init_lr\n",
        "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        )\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup\n",
        "            - (epoch - self.warmup_epochs)\n",
        "            * (self.lr_after_warmup - self.final_lr)\n",
        "            / (self.decay_epochs),\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        return self.calculate_lr(epoch)"
      ],
      "metadata": {
        "id": "odVc-SdMqqn6"
      },
      "id": "odVc-SdMqqn6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_ for _ in data]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(texts)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(ques,ans,bs=4):\n",
        "    ques_ds = create_text_ds(ques)\n",
        "    ans_ds = create_text_ds(ans)\n",
        "    ds = tf.data.Dataset.zip((ques_ds, ans_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "ggj-aLU_z2EF"
      },
      "id": "ggj-aLU_z2EF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(encoder_input_data) * 0.99)\n",
        "ques_train = encoder_input_data[:split]\n",
        "ques_test = encoder_input_data[split:]\n",
        "\n",
        "ans_train = decoder_input_data[:split]\n",
        "ans_test = decoder_input_data[split:]\n",
        "ds = create_tf_dataset(ques_train,ans_train, bs=64)\n",
        "val_ds = create_tf_dataset(ques_test,ans_test, bs=4)"
      ],
      "metadata": {
        "id": "NP8__EOi1SYK"
      },
      "id": "NP8__EOi1SYK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=2,\n",
        "    num_feed_forward=400,\n",
        "    source_maxlen=maxlen_questions,\n",
        "    target_maxlen=maxlen_answers,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=VOCAB_SIZE,\n",
        ")\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True, label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "learning_rate = CustomSchedule(\n",
        "    init_lr=0.01,\n",
        "    lr_after_warmup=0.1,\n",
        "    final_lr=0.01,\n",
        "    warmup_epochs=15,\n",
        "    decay_epochs=85,\n",
        "    steps_per_epoch=len(question_tokens),\n",
        ")\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n"
      ],
      "metadata": {
        "id": "lvRjtwl_quy0"
      },
      "id": "lvRjtwl_quy0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, validation_data=val_ds,epochs=150)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Zz3qe150qa",
        "outputId": "0b8b753d-a708-40b1-8444-ee24640d0b47"
      },
      "id": "84Zz3qe150qa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "71/71 [==============================] - 11s 75ms/step - loss: 1.2826 - val_loss: 0.6982\n",
            "Epoch 2/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.2385 - val_loss: 0.6596\n",
            "Epoch 3/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.1986 - val_loss: 0.6310\n",
            "Epoch 4/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.1680 - val_loss: 0.6112\n",
            "Epoch 5/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.1446 - val_loss: 0.5968\n",
            "Epoch 6/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.1259 - val_loss: 0.5858\n",
            "Epoch 7/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.1103 - val_loss: 0.5771\n",
            "Epoch 8/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.0969 - val_loss: 0.5699\n",
            "Epoch 9/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.0853 - val_loss: 0.5639\n",
            "Epoch 10/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0749 - val_loss: 0.5588\n",
            "Epoch 11/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0657 - val_loss: 0.5545\n",
            "Epoch 12/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0574 - val_loss: 0.5507\n",
            "Epoch 13/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0498 - val_loss: 0.5474\n",
            "Epoch 14/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0429 - val_loss: 0.5445\n",
            "Epoch 15/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0366 - val_loss: 0.5419\n",
            "Epoch 16/150\n",
            "71/71 [==============================] - 4s 63ms/step - loss: 1.0308 - val_loss: 0.5396\n",
            "Epoch 17/150\n",
            "71/71 [==============================] - 5s 67ms/step - loss: 1.0256 - val_loss: 0.5375\n",
            "Epoch 18/150\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 1.0207 - val_loss: 0.5357\n",
            "Epoch 19/150\n",
            "71/71 [==============================] - 6s 85ms/step - loss: 1.0163 - val_loss: 0.5340\n",
            "Epoch 20/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.0122 - val_loss: 0.5325\n",
            "Epoch 21/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0085 - val_loss: 0.5311\n",
            "Epoch 22/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 1.0051 - val_loss: 0.5299\n",
            "Epoch 23/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 1.0020 - val_loss: 0.5288\n",
            "Epoch 24/150\n",
            "71/71 [==============================] - 5s 66ms/step - loss: 0.9991 - val_loss: 0.5278\n",
            "Epoch 25/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9964 - val_loss: 0.5269\n",
            "Epoch 26/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9939 - val_loss: 0.5261\n",
            "Epoch 27/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9916 - val_loss: 0.5253\n",
            "Epoch 28/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9895 - val_loss: 0.5246\n",
            "Epoch 29/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9874 - val_loss: 0.5239\n",
            "Epoch 30/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9854 - val_loss: 0.5233\n",
            "Epoch 31/150\n",
            "71/71 [==============================] - 4s 63ms/step - loss: 0.9835 - val_loss: 0.5226\n",
            "Epoch 32/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9817 - val_loss: 0.5220\n",
            "Epoch 33/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9798 - val_loss: 0.5214\n",
            "Epoch 34/150\n",
            "71/71 [==============================] - 4s 63ms/step - loss: 0.9780 - val_loss: 0.5208\n",
            "Epoch 35/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9762 - val_loss: 0.5201\n",
            "Epoch 36/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9743 - val_loss: 0.5194\n",
            "Epoch 37/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9725 - val_loss: 0.5188\n",
            "Epoch 38/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9706 - val_loss: 0.5181\n",
            "Epoch 39/150\n",
            "71/71 [==============================] - 5s 66ms/step - loss: 0.9687 - val_loss: 0.5173\n",
            "Epoch 40/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9667 - val_loss: 0.5166\n",
            "Epoch 41/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9647 - val_loss: 0.5159\n",
            "Epoch 42/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9627 - val_loss: 0.5151\n",
            "Epoch 43/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9607 - val_loss: 0.5144\n",
            "Epoch 44/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9586 - val_loss: 0.5136\n",
            "Epoch 45/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9565 - val_loss: 0.5128\n",
            "Epoch 46/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9543 - val_loss: 0.5121\n",
            "Epoch 47/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9522 - val_loss: 0.5113\n",
            "Epoch 48/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9500 - val_loss: 0.5105\n",
            "Epoch 49/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9478 - val_loss: 0.5098\n",
            "Epoch 50/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9456 - val_loss: 0.5090\n",
            "Epoch 51/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.9433 - val_loss: 0.5082\n",
            "Epoch 52/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9411 - val_loss: 0.5075\n",
            "Epoch 53/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9388 - val_loss: 0.5068\n",
            "Epoch 54/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9366 - val_loss: 0.5060\n",
            "Epoch 55/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9343 - val_loss: 0.5053\n",
            "Epoch 56/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9321 - val_loss: 0.5046\n",
            "Epoch 57/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9298 - val_loss: 0.5039\n",
            "Epoch 58/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9275 - val_loss: 0.5032\n",
            "Epoch 59/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9253 - val_loss: 0.5025\n",
            "Epoch 60/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9231 - val_loss: 0.5018\n",
            "Epoch 61/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9208 - val_loss: 0.5011\n",
            "Epoch 62/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9186 - val_loss: 0.5005\n",
            "Epoch 63/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9164 - val_loss: 0.4999\n",
            "Epoch 64/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9141 - val_loss: 0.4987\n",
            "Epoch 65/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.9094 - val_loss: 0.4947\n",
            "Epoch 66/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8946 - val_loss: 0.4874\n",
            "Epoch 67/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8791 - val_loss: 0.4829\n",
            "Epoch 68/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8638 - val_loss: 0.4793\n",
            "Epoch 69/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8493 - val_loss: 0.4753\n",
            "Epoch 70/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8354 - val_loss: 0.4726\n",
            "Epoch 71/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8221 - val_loss: 0.4689\n",
            "Epoch 72/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.8091 - val_loss: 0.4659\n",
            "Epoch 73/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7968 - val_loss: 0.4613\n",
            "Epoch 74/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7850 - val_loss: 0.4588\n",
            "Epoch 75/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7739 - val_loss: 0.4569\n",
            "Epoch 76/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7655 - val_loss: 0.4564\n",
            "Epoch 77/150\n",
            "71/71 [==============================] - 5s 74ms/step - loss: 0.7550 - val_loss: 0.4528\n",
            "Epoch 78/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.7435 - val_loss: 0.4521\n",
            "Epoch 79/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7329 - val_loss: 0.4485\n",
            "Epoch 80/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7224 - val_loss: 0.4441\n",
            "Epoch 81/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7119 - val_loss: 0.4384\n",
            "Epoch 82/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.7022 - val_loss: 0.4350\n",
            "Epoch 83/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6926 - val_loss: 0.4283\n",
            "Epoch 84/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6835 - val_loss: 0.4285\n",
            "Epoch 85/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6742 - val_loss: 0.4314\n",
            "Epoch 86/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.6668 - val_loss: 0.4293\n",
            "Epoch 87/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6576 - val_loss: 0.4264\n",
            "Epoch 88/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6472 - val_loss: 0.4187\n",
            "Epoch 89/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.6381 - val_loss: 0.4131\n",
            "Epoch 90/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.6265 - val_loss: 0.4124\n",
            "Epoch 91/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6154 - val_loss: 0.4118\n",
            "Epoch 92/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.6047 - val_loss: 0.4077\n",
            "Epoch 93/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5949 - val_loss: 0.4069\n",
            "Epoch 94/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5843 - val_loss: 0.4078\n",
            "Epoch 95/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5719 - val_loss: 0.4071\n",
            "Epoch 96/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5601 - val_loss: 0.4086\n",
            "Epoch 97/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5491 - val_loss: 0.4144\n",
            "Epoch 98/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.5381 - val_loss: 0.4122\n",
            "Epoch 99/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5285 - val_loss: 0.4063\n",
            "Epoch 100/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5199 - val_loss: 0.4004\n",
            "Epoch 101/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.5095 - val_loss: 0.3987\n",
            "Epoch 102/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4978 - val_loss: 0.3962\n",
            "Epoch 103/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4861 - val_loss: 0.3963\n",
            "Epoch 104/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4753 - val_loss: 0.3963\n",
            "Epoch 105/150\n",
            "71/71 [==============================] - 5s 66ms/step - loss: 0.4652 - val_loss: 0.3958\n",
            "Epoch 106/150\n",
            "71/71 [==============================] - 5s 66ms/step - loss: 0.4545 - val_loss: 0.3944\n",
            "Epoch 107/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4447 - val_loss: 0.3956\n",
            "Epoch 108/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4360 - val_loss: 0.3985\n",
            "Epoch 109/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.4287 - val_loss: 0.3994\n",
            "Epoch 110/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.4208 - val_loss: 0.3988\n",
            "Epoch 111/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.4127 - val_loss: 0.3994\n",
            "Epoch 112/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.4048 - val_loss: 0.4046\n",
            "Epoch 113/150\n",
            "71/71 [==============================] - 5s 76ms/step - loss: 0.3968 - val_loss: 0.4028\n",
            "Epoch 114/150\n",
            "71/71 [==============================] - 5s 70ms/step - loss: 0.3877 - val_loss: 0.4019\n",
            "Epoch 115/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3779 - val_loss: 0.4019\n",
            "Epoch 116/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3690 - val_loss: 0.4006\n",
            "Epoch 117/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3616 - val_loss: 0.4001\n",
            "Epoch 118/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3545 - val_loss: 0.4026\n",
            "Epoch 119/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.3479 - val_loss: 0.4069\n",
            "Epoch 120/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3416 - val_loss: 0.4146\n",
            "Epoch 121/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3358 - val_loss: 0.4153\n",
            "Epoch 122/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.3304 - val_loss: 0.4153\n",
            "Epoch 123/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.3247 - val_loss: 0.4096\n",
            "Epoch 124/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.3182 - val_loss: 0.4093\n",
            "Epoch 125/150\n",
            "71/71 [==============================] - 5s 68ms/step - loss: 0.3131 - val_loss: 0.4134\n",
            "Epoch 126/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.3080 - val_loss: 0.4158\n",
            "Epoch 127/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.3021 - val_loss: 0.4154\n",
            "Epoch 128/150\n",
            "71/71 [==============================] - 5s 68ms/step - loss: 0.2962 - val_loss: 0.4156\n",
            "Epoch 129/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2908 - val_loss: 0.4159\n",
            "Epoch 130/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2910 - val_loss: 0.4124\n",
            "Epoch 131/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2946 - val_loss: 0.4076\n",
            "Epoch 132/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2919 - val_loss: 0.4097\n",
            "Epoch 133/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2836 - val_loss: 0.4201\n",
            "Epoch 134/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2730 - val_loss: 0.4178\n",
            "Epoch 135/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2632 - val_loss: 0.4227\n",
            "Epoch 136/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2567 - val_loss: 0.4227\n",
            "Epoch 137/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2508 - val_loss: 0.4225\n",
            "Epoch 138/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2452 - val_loss: 0.4228\n",
            "Epoch 139/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2411 - val_loss: 0.4301\n",
            "Epoch 140/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2387 - val_loss: 0.4300\n",
            "Epoch 141/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2371 - val_loss: 0.4264\n",
            "Epoch 142/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2352 - val_loss: 0.4416\n",
            "Epoch 143/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2346 - val_loss: 0.4491\n",
            "Epoch 144/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2349 - val_loss: 0.4442\n",
            "Epoch 145/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2367 - val_loss: 0.4324\n",
            "Epoch 146/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2365 - val_loss: 0.4375\n",
            "Epoch 147/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2310 - val_loss: 0.4375\n",
            "Epoch 148/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2270 - val_loss: 0.4467\n",
            "Epoch 149/150\n",
            "71/71 [==============================] - 5s 64ms/step - loss: 0.2235 - val_loss: 0.4272\n",
            "Epoch 150/150\n",
            "71/71 [==============================] - 5s 65ms/step - loss: 0.2215 - val_loss: 0.4267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QN8x1jKPHOD"
      },
      "id": "-QN8x1jKPHOD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}